# -*- coding: utf-8 -*-
"""Hackathon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pH1sCyxLChR4uRzuDRcSIhT7YjhfkJwP
"""

import numpy as np
import cv2
import tensorflow as tf
import keras
import scipy

def crop_image(image):
    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
    faces = face_cascade.detectMultiScale(image, 1.3, 5)
    biggest = 0
    if len(faces) != 0:
        for face in faces :  
            area = face[2]*face[3]
            if area > biggest :
                biggest = area
                x = face[0]
                y = face[1]
                w = face[2]
                h = face[3]
        x = 0 if x < 0 else x
        y = 0 if y < 0 else y
        r = max(w, h) / 2
        centerx = x + w / 2
        centery = y + h / 2
        nx = int(centerx - r)
        ny = int(centery - r)
        nr = int(r * 2)
        faceimg = image[ny:ny+nr, nx:nx+nr]
        faceimg = cv2.resize(faceimg,(255,255))
        
        return faceimg
    else:
        return image

def image_parameters_to_array(X):
   X = np.squeeze(np.array(X, dtype= np.float32))
   X = np.resize(X,(X.shape[0],32,32,3))
   return X

def image_preprocessing(selfie_img, passport_img):
  selfie_img = cv2.cvtColor(selfie_img, cv2.COLOR_BGR2GRAY)
  passport_img = cv2.cvtColor(passport_img, cv2.COLOR_BGR2GRAY)
  selfie_img = cv2.resize(selfie_img,(255,255))
  passport_img = cv2.resize(passport_img,(255,255))
  selfie_img = crop_image(selfie_img)
  passport_img = crop_image(passport_img)
  return selfie_img, passport_img

print('Enter Selfie image Name :')
selfie_img = cv2.imread(input())
print('Enter Passport image Name :')
passport_img = cv2.imread(input())

selfie_img, passport_img = image_preprocessing(selfie_img,passport_img)

selfie_img = image_parameters_to_array(selfie_img)
passport_img = image_parameters_to_array(passport_img)

new_model = tf.keras.models.load_model('saved_model/my_model')

new_model.pop() # Remove Dense layer 
new_model.pop() # Remove Dense layer 
new_model.pop() # Remove Dense layer

new_model.summary() # Summary of loaded model , notice there are no Dense layers in Output

passport_vector = new_model.predict(passport_img) # Image Embedding Vector of passport image
magnitude_passport_vector = np.linalg.norm(passport_vector,axis=1) # Magnitude of Image Embedding Vector

selfie_vector = new_model.predict(selfie_img)  #Image Embedding Vector of selfie image
magnitude_selfie_vector = np.linalg.norm(selfie_vector,axis=1) # Magnitude of Image Embedding Vector

cosine_distance = scipy.spatial.distance.cosine(passport_vector.reshape(1,-1),selfie_vector.reshape(1,-1)) # Cosine_distance betweeen two vectors

similarity = (1 - cosine_distance)*100

if round(similarity,2) > 50 : 
  print('The input Images are ',round(similarity,2), '% Similar')
else:
  print('Images are not Similar')